{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ASPEKTU NOSKAŅOJUMA NOTEIKŠANA"
      ],
      "metadata": {
        "id": "U-eP5McbUYoA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ParuhCC0UToz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ef823d-39e2-4012-f349-e677f01ce38a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "5  lv_OPaps_000000002:1  Vienīgi cenas pēdējā laikā diezgan palielināju...   \n",
            "6  lv_OPaps_000000002:2  Latvijas alus ir labā cenā, bet izlejamais imp...   \n",
            "7  lv_OPaps_000000002:3  Cepelīni garšīgi, teikšu, ka pagaidām labākie,...   \n",
            "8   lv_OPaps_00000002:4  Baraviku zupa garšīga, bet, manuprāt, 11€ ir m...   \n",
            "9  lv_OPaps_000000002:5         Ķiploku grauzdiņi ir ļoti gardi un viegli.   \n",
            "\n",
            "                                    aspects  \n",
            "0                                   [vieta]  \n",
            "1                   [ēdieniem, alus izlase]  \n",
            "2                            [lielopa gaļa]  \n",
            "3                             [apkalpošana]  \n",
            "4                        [ēdieni, dzērieni]  \n",
            "5                                    [NULL]  \n",
            "6  [Latvijas alus, izlejamais importa alus]  \n",
            "7                                [Cepelīni]  \n",
            "8            [Baraviku zupa, Baraviku zupa]  \n",
            "9                       [Ķiploku grauzdiņi]  \n",
            "vieta:positive\n",
            "ēdieniem:positive\n",
            "alus izlase:positive\n",
            "lielopa gaļa:positive\n",
            "apkalpošana:positive\n",
            "ēdieni:positive\n",
            "dzērieni:positive\n",
            "latvijas alus:neutral\n",
            "izlejamais importa alus:negative\n",
            "cepelīni:positive\n",
            "baraviku zupa:negative\n",
            "baraviku zupa:neutral\n",
            "ķiploku grauzdiņi:positive\n",
            "\n",
            " Results have been saved to results_sentiments.txt\n"
          ]
        }
      ],
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def parse_xml_sentiment_pred(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                aspects.append(target)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml_sentiment_pred('new1.xml')\n",
        "print(df_test)\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def predict_sentiment(aspect, sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given an aspect term and a sentence, predict the sentiment towards the given aspect (positive, negative, neutral).\\n\\n\"\n",
        "        f\"Aspect term: '{aspect}'\\nSentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect:polarity\\n\"\n",
        "        \"Example: service:positive\\n\"\n",
        "        \"Do not provide any additional text or explanation.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    pred = completion.choices[0].message.content.strip().lower()\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "    if ':' in pred:\n",
        "        return pred\n",
        "    else:\n",
        "        return f\"{aspect}:{pred}\"\n",
        "\n",
        "output_file = 'results_sentiments.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "  for idx, row in df_test.iterrows():\n",
        "    sentence_text = row['text']\n",
        "    aspect_preds = []\n",
        "    if len(row['aspects']) == 0:\n",
        "      continue\n",
        "    for aspect in row['aspects']:\n",
        "      if aspect.lower() == \"null\":\n",
        "        continue\n",
        "      pred = predict_sentiment(aspect, sentence_text)\n",
        "      print(pred)\n",
        "      aspect_preds.append(pred.strip())\n",
        "    if aspect_preds:\n",
        "      f.write(\", \".join(aspect_preds) + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target and target.lower() != \"null\":\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, pred_list):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    mismatches = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        pred_aspects = pred_list[i]['aspects']\n",
        "        pred_sentiments = pred_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == pred_aspects and true_sentiments == pred_sentiments:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(0)\n",
        "            mismatches.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'pred_aspects': pred_aspects,\n",
        "                'pred_sentiments': pred_sentiments\n",
        "            })\n",
        "    print(accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"Nepareizi\", \"Pareizi\"]))\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_sentiments.txt'\n",
        "df_test = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(df_test) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(df_test, predictions)"
      ],
      "metadata": {
        "id": "931l-hb8U71w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315f0e09-3149-4f30-a032-0568fb6c8988"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "0.7777777777777778\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Nepareizi       0.00      0.00      0.00         0\n",
            "     Pareizi       1.00      0.78      0.88         9\n",
            "\n",
            "    accuracy                           0.78         9\n",
            "   macro avg       0.50      0.39      0.44         9\n",
            "weighted avg       1.00      0.78      0.88         9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ASPEKTU IZGŪŠANA"
      ],
      "metadata": {
        "id": "y8H4gW34_zE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def parse_xml_aspect_extraction(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        data.append({\n",
        "            'id': sentence.get('id'),\n",
        "            'text': text\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml_aspect_extraction('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect term extraction.\\n\"\n",
        "        \"Given a sentence, extract all aspect terms mentioned in the sentence.\\n\"\n",
        "        \"If there is no explicit aspect in a whole sentence or in an exact part of a sentence, give answer 'null'.\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY with aspect terms, comma-separated.\\n\"\n",
        "        \"Example: service, food\\n\"\n",
        "        \"Do not provide any additional text or explanation.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    pred = completion.choices[0].message.content.strip().lower()\n",
        "    return pred\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: kā uzlabot šo koda daļu, lai tas būtu piemērots izgūtu aspektu saglabāšanai? https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "output_file = 'results_aspects.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in df_test.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        pred_aspects = extract_aspects(sentence_text)\n",
        "        if pred_aspects:\n",
        "            f.write(pred_aspects + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3liWvuE8_1Pm",
        "outputId": "3d7337dc-4612-419c-e61f-506bb2335166"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "\n",
            " Results have been saved to results_aspects.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                if target:\n",
        "                  aspects.append(target.lower())\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect, aspect formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_list = [aspect.strip().lower() for aspect in line.split(',') if aspect.strip()]\n",
        "            predictions.append({\n",
        "                'aspects': aspect_list\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, pred_list):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    mismatches = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        pred_aspects = pred_list[i]['aspects']\n",
        "        if true_aspects == pred_aspects:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(0)\n",
        "            mismatches.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'pred_aspects': pred_aspects\n",
        "            })\n",
        "    print(accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"Nepareizi\", \"Pareizi\"]))\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_aspects.txt'\n",
        "df_test = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(df_test) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(df_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaIBwcwKBQbu",
        "outputId": "d8157062-3e00-418c-99df-d93e803c1bf8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects  \n",
            "0                  [vieta]  \n",
            "1  [ēdieniem, alus izlase]  \n",
            "2           [lielopa gaļa]  \n",
            "3            [apkalpošana]  \n",
            "4       [ēdieni, dzērieni]  \n",
            "0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Nepareizi       0.00      0.00      0.00       0.0\n",
            "     Pareizi       0.00      0.00      0.00      10.0\n",
            "\n",
            "    accuracy                           0.00      10.0\n",
            "   macro avg       0.00      0.00      0.00      10.0\n",
            "weighted avg       0.00      0.00      0.00      10.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIENLAICĪGA ASPEKTU IZGŪŠANA UN TO NOSKAŅOJUMU NOTEIKŠANA"
      ],
      "metadata": {
        "id": "4zMLdV98Mtw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def parse_xml_full_absa(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        data.append({\n",
        "            'id': sentence.get('id'),\n",
        "            'text': text\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml_full_absa('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects_predict_sentiment(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given a sentence, extract all aspect terms mentioned in the sentence and predict the sentiments towards the extracted aspects (positive, negative, neutral).\\n\\n\"\n",
        "        \"If there is no explicit aspect in a whole sentence or in an exact part of a sentence, give answer 'null'.\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect1:polarity1, aspect2:polarity2\\n\"\n",
        "        \"Example: service:positive, food:negative\\n\"\n",
        "        \"Do not provide any additional text or explanation.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"google/gemma-3-27b-it:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    pred = completion.choices[0].message.content.strip().lower()\n",
        "\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "    if ':' in pred:\n",
        "        return pred\n",
        "    else:\n",
        "        return f\"{aspect}:{pred}\"\n",
        "\n",
        "output_file = 'results_full.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in df_test.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        pred = extract_aspects_predict_sentiment(sentence_text)\n",
        "        if pred:\n",
        "            f.write(pred + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vt4_9KQMvYw",
        "outputId": "782bdea0-7cfa-429c-b6df-80c3489392bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "\n",
            " Results have been saved to results_full.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target:\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, pred_list):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    mismatches = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        pred_aspects = pred_list[i]['aspects']\n",
        "        pred_sentiments = pred_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == pred_aspects and true_sentiments == pred_sentiments:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(0)\n",
        "            mismatches.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'pred_aspects': pred_aspects,\n",
        "                'pred_sentiments': pred_sentiments\n",
        "            })\n",
        "    print(accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"Nepareizi\", \"Pareizi\"]))\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_full.txt'\n",
        "df_test = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(df_test) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(df_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vJrczm6OMlD",
        "outputId": "a1c358c3-7052-497e-a01d-209e082e5ce3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "0.3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Nepareizi       0.00      0.00      0.00         0\n",
            "     Pareizi       1.00      0.30      0.46        10\n",
            "\n",
            "    accuracy                           0.30        10\n",
            "   macro avg       0.50      0.15      0.23        10\n",
            "weighted avg       1.00      0.30      0.46        10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIENLAICĪGA ASPEKTU IZGŪŠANA UN TO NOSKAŅOJUMU NOTEIKŠANA AR PIEMĒRU"
      ],
      "metadata": {
        "id": "c_KP_rJITX1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def parse_xml_full_absa_with_examples(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        data.append({\n",
        "            'id': sentence.get('id'),\n",
        "            'text': text\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml_full_absa_with_examples('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects_predict_sentiment(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given a sentence, extract all aspect terms mentioned in the sentence and predict the sentiments towards the aspects (positive, negative, neutral).\\n\\n\"\n",
        "        \"Example:\\n\"\n",
        "        \"Sentence: Vīnu saraksts ir interesants, un tajā ir daudz labu piedāvājumu.\\n\"\n",
        "        \"Vīnu saraksts:positive, Vīnu saraksts:negative\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect1:polarity1, aspect2:polarity2\\n\"\n",
        "        \"Example: service:positive, food:negative\\n\"\n",
        "        \"Do not provide any additional text or explanation.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"google/gemma-3-27b-it:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    pred = completion.choices[0].message.content.strip().lower()\n",
        "\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "    if ':' in pred:\n",
        "        return pred\n",
        "    else:\n",
        "        return f\"{aspect}:{pred}\"\n",
        "\n",
        "output_file = 'results_full_with_examples.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in df_test.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        pred = extract_aspects_predict_sentiment(sentence_text)\n",
        "        if pred:\n",
        "            f.write(pred + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOqVGOsiTZsp",
        "outputId": "643fb6f0-27ca-4bbc-e15f-317c2c5d9001"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "\n",
            " Results have been saved to results_full_with_examples.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target:\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, pred_list):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    mismatches = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        pred_aspects = pred_list[i]['aspects']\n",
        "        pred_sentiments = pred_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == pred_aspects and true_sentiments == pred_sentiments:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(0)\n",
        "            mismatches.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'pred_aspects': pred_aspects,\n",
        "                'pred_sentiments': pred_sentiments\n",
        "            })\n",
        "    print(accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"Nepareizi\", \"Pareizi\"]))\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_full_with_examples.txt'\n",
        "df_test = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(df_test) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(df_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-ro3sQETxP1",
        "outputId": "975d6700-1b7b-4952-a0d5-aca4676a0e2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "0.3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Nepareizi       0.00      0.00      0.00         0\n",
            "     Pareizi       1.00      0.30      0.46        10\n",
            "\n",
            "    accuracy                           0.30        10\n",
            "   macro avg       0.50      0.15      0.23        10\n",
            "weighted avg       1.00      0.30      0.46        10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}