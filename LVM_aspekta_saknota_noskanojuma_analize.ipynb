{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ASPEKTU NOSKAŅOJUMA NOTEIKŠANA"
      ],
      "metadata": {
        "id": "U-eP5McbUYoA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ParuhCC0UToz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf27b73c-f2b0-4d8e-f6cd-06483e464ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "5  lv_OPaps_000000002:2  Latvijas alus ir labā cenā, bet izlejamais imp...   \n",
            "6  lv_OPaps_000000002:3  Cepelīni garšīgi, teikšu, ka pagaidām labākie,...   \n",
            "7   lv_OPaps_00000002:4  Baraviku zupa garšīga, bet, manuprāt, 11€ ir m...   \n",
            "8  lv_OPaps_000000002:5         Ķiploku grauzdiņi ir ļoti gardi un viegli.   \n",
            "\n",
            "                                    aspects  \n",
            "0                                   [vieta]  \n",
            "1                   [ēdieniem, alus izlase]  \n",
            "2                            [lielopa gaļa]  \n",
            "3                             [apkalpošana]  \n",
            "4                        [ēdieni, dzērieni]  \n",
            "5  [Latvijas alus, izlejamais importa alus]  \n",
            "6                                [Cepelīni]  \n",
            "7            [Baraviku zupa, Baraviku zupa]  \n",
            "8                       [Ķiploku grauzdiņi]  \n",
            "vieta:positive\n",
            "ēdieniem:positive\n",
            "alus izlase:positive\n",
            "lielopa gaļa:positive\n",
            "apkalpošana:positive\n",
            "ēdieni:positive\n",
            "dzērieni:positive\n",
            "latvijas alus:neutral\n",
            "izlejamais importa alus:negative\n",
            "cepelīni:positive\n",
            "baraviku zupa:negative\n",
            "baraviku zupa:positive\n",
            "ķiploku grauzdiņi:positive\n",
            "\n",
            " Results have been saved to results_sentiments.txt\n"
          ]
        }
      ],
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "def parse_xml_sentiment_pred(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                if target and target.lower() != \"null\":\n",
        "                  aspects.append(target)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "test_data = parse_xml_sentiment_pred('new1.xml')\n",
        "print(test_data)\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def predict_sentiment(aspect, sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given an aspect term and a sentence, predict the sentiment towards the given aspect (positive, negative, neutral).\\n\\n\"\n",
        "        f\"Aspect term: '{aspect}'\\nSentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect:polarity\\n\"\n",
        "        \"Example: apkalpošana:positive\\n\"\n",
        "        \"Do not provide any additional text or explanation.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    prediction = completion.choices[0].message.content.strip().lower()\n",
        "    return prediction\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "output_file = 'results_sentiments.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "  for idx, row in test_data.iterrows():\n",
        "    sentence_text = row['text']\n",
        "    aspect_predictions = []\n",
        "    for aspect in row['aspects']:\n",
        "      prediction = predict_sentiment(aspect, sentence_text)\n",
        "      print(prediction)\n",
        "      aspect_predictions.append(prediction.strip())\n",
        "    if aspect_predictions:\n",
        "      f.write(\", \".join(aspect_predictions) + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target and target.lower() != \"null\":\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "test_data = parse_xml('new1.xml')\n",
        "print(test_data.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(test_data, prediction_list):\n",
        "    correct_results = []\n",
        "    predictions = []\n",
        "    mismatching_answers = []\n",
        "\n",
        "    for i, row in test_data.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        predicted_aspects = prediction_list[i]['aspects']\n",
        "        predicted_sentiments = prediction_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == predicted_aspects and true_sentiments == predicted_sentiments:\n",
        "            correct_results.append(1)\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            correct_results.append(1)\n",
        "            predictions.append(0)\n",
        "            mismatching_answers.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'predicted_aspects': predicted_aspects,\n",
        "                'predicted_sentiments': predicted_sentiments\n",
        "            })\n",
        "    print(f\"\\nAccuracy: {accuracy_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nPrecision: {precision_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nRecall: {recall_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nF1 score: {f1_score(correct_results, predictions)}\")\n",
        "    if mismatching_answers:\n",
        "        for mismatch in mismatching_answers:\n",
        "            print(f\"\\nSentence: {mismatch['text']}\")\n",
        "            print(f\"Correct answer: {list(zip(mismatch['true_aspects'], mismatch['true_sentiments']))}\")\n",
        "            print(f\"LLM answer: {list(zip(mismatch['predicted_aspects'], mismatch['predicted_sentiments']))}\")\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_sentiments.txt'\n",
        "test_data = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(test_data) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(test_data, predictions)"
      ],
      "metadata": {
        "id": "931l-hb8U71w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ee8a1f-8902-48e9-d961-490500cd773f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "\n",
            "Accuracy: 0.7777777777777778\n",
            "\n",
            "Precision: 1.0\n",
            "\n",
            "Recall: 0.7777777777777778\n",
            "\n",
            "F1 score: 0.875\n",
            "\n",
            "Sentence: Latvijas alus ir labā cenā, bet izlejamais importa alus jau maksā ap 7€ par puslitru.\n",
            "Correct answer: [('latvijas alus', 'positive'), ('izlejamais importa alus', 'neutral')]\n",
            "LLM answer: [('latvijas alus', 'neutral'), ('izlejamais importa alus', 'negative')]\n",
            "\n",
            "Sentence: Baraviku zupa garšīga, bet, manuprāt, 11€ ir mazliet par dārgu priekš šīs zupas un tās daudzuma.\n",
            "Correct answer: [('baraviku zupa', 'positive'), ('baraviku zupa', 'negative')]\n",
            "LLM answer: [('baraviku zupa', 'negative'), ('baraviku zupa', 'positive')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ASPEKTU IZGŪŠANA"
      ],
      "metadata": {
        "id": "y8H4gW34_zE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "def parse_xml_aspect_extraction(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        if opinions is not None:\n",
        "          for opinion in opinions.findall('Opinion'):\n",
        "            target = opinion.get('target')\n",
        "            if target:\n",
        "              aspects.append(target)\n",
        "        if aspects and all(aspect.lower() != \"null\" for aspect in aspects):\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "test_data = parse_xml_aspect_extraction('new1.xml')\n",
        "print(test_data)\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect term extraction.\\n\"\n",
        "        \"Given a sentence, extract all explicit aspect terms mentioned in the sentence.\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY with aspect terms, comma-separated.\\n\"\n",
        "        \"Example: apkalpošana, ēdienu\\n\"\n",
        "        \"Do not provide any additional text or explanation and do not guess implicit aspects.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    prediction = completion.choices[0].message.content.strip().lower()\n",
        "    return prediction\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: kā uzlabot šo koda daļu, lai tas būtu piemērots izgūtu aspektu saglabāšanai? https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "output_file = 'results_aspects.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in test_data.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        predicted_aspects = extract_aspects(sentence_text)\n",
        "        if predicted_aspects:\n",
        "            f.write(predicted_aspects + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3liWvuE8_1Pm",
        "outputId": "566ebef3-5280-4baf-f4f1-c02914f9da22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "5  lv_OPaps_000000002:2  Latvijas alus ir labā cenā, bet izlejamais imp...\n",
            "6  lv_OPaps_000000002:3  Cepelīni garšīgi, teikšu, ka pagaidām labākie,...\n",
            "7   lv_OPaps_00000002:4  Baraviku zupa garšīga, bet, manuprāt, 11€ ir m...\n",
            "8  lv_OPaps_000000002:5         Ķiploku grauzdiņi ir ļoti gardi un viegli.\n",
            "\n",
            " Results have been saved to results_aspects.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                if target and target.lower() != \"null\":\n",
        "                  aspects.append(target.lower())\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "test_data = parse_xml('new1.xml')\n",
        "print(test_data)\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect, aspect formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_list = [aspect.strip().lower() for aspect in line.split(',') if aspect.strip()]\n",
        "            predictions.append({\n",
        "                'aspects': aspect_list\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(test_data, prediction_list):\n",
        "    correct_results = []\n",
        "    predictions = []\n",
        "    mismatching_answers = []\n",
        "\n",
        "    for i, row in test_data.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        predicted_aspects = prediction_list[i]['aspects']\n",
        "        if true_aspects == predicted_aspects:\n",
        "            correct_results.append(1)\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            correct_results.append(1)\n",
        "            predictions.append(0)\n",
        "            mismatching_answers.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'predicted_aspects': predicted_aspects\n",
        "            })\n",
        "    print(f\"\\nAccuracy: {accuracy_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nPrecision: {precision_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nRecall: {recall_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nF1 score: {f1_score(correct_results, predictions)}\")\n",
        "    if mismatching_answers:\n",
        "        for mismatch in mismatching_answers:\n",
        "            print(f\"\\nSentence: {mismatch['text']}\")\n",
        "            print(f\"Correct answer: {list(mismatch['true_aspects'])}\")\n",
        "            print(f\"LLM answer: {list(mismatch['predicted_aspects'])}\")\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_aspects.txt'\n",
        "test_data = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(test_data) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(test_data, predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaIBwcwKBQbu",
        "outputId": "550fabd4-3b90-4916-a93a-b7d12d8f9e74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "5  lv_OPaps_000000002:2  Latvijas alus ir labā cenā, bet izlejamais imp...   \n",
            "6  lv_OPaps_000000002:3  Cepelīni garšīgi, teikšu, ka pagaidām labākie,...   \n",
            "7   lv_OPaps_00000002:4  Baraviku zupa garšīga, bet, manuprāt, 11€ ir m...   \n",
            "8  lv_OPaps_000000002:5         Ķiploku grauzdiņi ir ļoti gardi un viegli.   \n",
            "\n",
            "                                    aspects  \n",
            "0                                   [vieta]  \n",
            "1                   [ēdieniem, alus izlase]  \n",
            "2                            [lielopa gaļa]  \n",
            "3                             [apkalpošana]  \n",
            "4                        [ēdieni, dzērieni]  \n",
            "5  [latvijas alus, izlejamais importa alus]  \n",
            "6                                [cepelīni]  \n",
            "7            [baraviku zupa, baraviku zupa]  \n",
            "8                       [ķiploku grauzdiņi]  \n",
            "\n",
            "Accuracy: 0.2222222222222222\n",
            "\n",
            "Precision: 1.0\n",
            "\n",
            "Recall: 0.2222222222222222\n",
            "\n",
            "F1 score: 0.36363636363636365\n",
            "\n",
            "Sentence: Lieliska vieta vakariņām.\n",
            "Correct answer: ['vieta']\n",
            "LLM answer: ['vieta', 'vakariņām']\n",
            "\n",
            "Sentence: Ļoti draudzīgas cenas ēdieniem un laba vietējā alus izlase.\n",
            "Correct answer: ['ēdieniem', 'alus izlase']\n",
            "LLM answer: ['cenas', 'ēdieniem', 'alus izlase']\n",
            "\n",
            "Sentence: Ēdieniem īpaši garda un augstvērtīga lielopa gaļa.\n",
            "Correct answer: ['lielopa gaļa']\n",
            "LLM answer: ['ēdieniem', 'lietopa gaļa']\n",
            "\n",
            "Sentence: Perfekta apkalpošana, prot ieteikt lieliskus ēdienus.\n",
            "Correct answer: ['apkalpošana']\n",
            "LLM answer: ['apkalpošana', 'ēdienus']\n",
            "\n",
            "Sentence: Latvijas alus ir labā cenā, bet izlejamais importa alus jau maksā ap 7€ par puslitru.\n",
            "Correct answer: ['latvijas alus', 'izlejamais importa alus']\n",
            "LLM answer: ['latvijas alus', 'cena', 'importa alus', 'maksā', 'puslitru']\n",
            "\n",
            "Sentence: Baraviku zupa garšīga, bet, manuprāt, 11€ ir mazliet par dārgu priekš šīs zupas un tās daudzuma.\n",
            "Correct answer: ['baraviku zupa', 'baraviku zupa']\n",
            "LLM answer: ['zupa', 'priekš šīs zupas', 'tās daudzuma']\n",
            "\n",
            "Sentence: Ķiploku grauzdiņi ir ļoti gardi un viegli.\n",
            "Correct answer: ['ķiploku grauzdiņi']\n",
            "LLM answer: ['grauzdiņi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIENLAICĪGA ASPEKTU IZGŪŠANA UN TO NOSKAŅOJUMU NOTEIKŠANA"
      ],
      "metadata": {
        "id": "4zMLdV98Mtw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "def parse_xml_full_absa(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        if opinions is not None:\n",
        "          for opinion in opinions.findall('Opinion'):\n",
        "            target = opinion.get('target')\n",
        "            if target:\n",
        "              aspects.append(target)\n",
        "        if aspects and all(aspect.lower() != \"null\" for aspect in aspects):\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "test_data = parse_xml_full_absa('new1.xml')\n",
        "print(test_data)\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects_predict_sentiment(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given a sentence, extract all explicit aspect terms mentioned in the sentence and predict the sentiments towards the extracted aspects (positive, negative, neutral).\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect1:polarity1, aspect2:polarity2\\n\"\n",
        "        \"Example: apkalpošana:positive, ēdienu:negative\\n\"\n",
        "        \"Do not provide any additional text or explanation and do not guess implicit aspects.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"google/gemma-3-27b-it:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    prediction = completion.choices[0].message.content.strip().lower()\n",
        "    return prediction\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "output_file = 'results_full.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in test_data.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        prediction = extract_aspects_predict_sentiment(sentence_text)\n",
        "        if prediction:\n",
        "            f.write(prediction + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vt4_9KQMvYw",
        "outputId": "6c6c54a8-9365-42a0-939b-a438ce49cb69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "5  lv_OPaps_000000002:2  Latvijas alus ir labā cenā, bet izlejamais imp...\n",
            "6  lv_OPaps_000000002:3  Cepelīni garšīgi, teikšu, ka pagaidām labākie,...\n",
            "7   lv_OPaps_00000002:4  Baraviku zupa garšīga, bet, manuprāt, 11€ ir m...\n",
            "8  lv_OPaps_000000002:5         Ķiploku grauzdiņi ir ļoti gardi un viegli.\n",
            "\n",
            " Results have been saved to results_full.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target and target.lower() != \"null\":\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "test_data = parse_xml('new1.xml')\n",
        "print(test_data.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, prediction_list):\n",
        "    correct_results = []\n",
        "    predictions = []\n",
        "    mismatching_answers = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        predicted_aspects = prediction_list[i]['aspects']\n",
        "        predicted_sentiments = prediction_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == predicted_aspects and true_sentiments == predicted_sentiments:\n",
        "            correct_results.append(1)\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            correct_results.append(1)\n",
        "            predictions.append(0)\n",
        "            mismatching_answers.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'predicted_aspects': predicted_aspects,\n",
        "                'predicted_sentiments': predicted_sentiments\n",
        "            })\n",
        "    print(f\"\\nAccuracy: {accuracy_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nPrecision: {precision_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nRecall: {recall_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nF1 score: {f1_score(correct_results, predictions)}\")\n",
        "    if mismatching_answers:\n",
        "        for mismatch in mismatching_answers:\n",
        "            print(f\"\\nSentence: {mismatch['text']}\")\n",
        "            print(f\"Correct answer: {list(zip(mismatch['true_aspects'], mismatch['true_sentiments']))}\")\n",
        "            print(f\"LLM answer: {list(zip(mismatch['predicted_aspects'], mismatch['predicted_sentiments']))}\")\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_full.txt'\n",
        "test_data = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(test_data) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(test_data, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vJrczm6OMlD",
        "outputId": "1589bf12-f064-49d0-f937-cee0c66b1ef0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "\n",
            "Accuracy: 0.3333333333333333\n",
            "\n",
            "Precision: 1.0\n",
            "\n",
            "Recall: 0.3333333333333333\n",
            "\n",
            "F1 score: 0.5\n",
            "\n",
            "Sentence: Ļoti draudzīgas cenas ēdieniem un laba vietējā alus izlase.\n",
            "Correct answer: [('ēdieniem', 'positive'), ('alus izlase', 'positive')]\n",
            "LLM answer: [('cenas', 'positive'), ('alus izlase', 'positive')]\n",
            "\n",
            "Sentence: Ēdieniem īpaši garda un augstvērtīga lielopa gaļa.\n",
            "Correct answer: [('lielopa gaļa', 'positive')]\n",
            "LLM answer: [('lielopa gaļa', 'positive'), ('ēdieniem', 'positive')]\n",
            "\n",
            "Sentence: Perfekta apkalpošana, prot ieteikt lieliskus ēdienus.\n",
            "Correct answer: [('apkalpošana', 'positive')]\n",
            "LLM answer: [('apkalpošana', 'positive'), ('ēdienus', 'positive')]\n",
            "\n",
            "Sentence: Latvijas alus ir labā cenā, bet izlejamais importa alus jau maksā ap 7€ par puslitru.\n",
            "Correct answer: [('latvijas alus', 'positive'), ('izlejamais importa alus', 'neutral')]\n",
            "LLM answer: [('', 'alus:positive'), ('cenas', 'positive'), ('alus', 'negative')]\n",
            "\n",
            "Sentence: Cepelīni garšīgi, teikšu, ka pagaidām labākie, kurus Latvijā esmu ēdis.\n",
            "Correct answer: [('cepelīni', 'positive')]\n",
            "LLM answer: [('', 'cepelīni:positive')]\n",
            "\n",
            "Sentence: Baraviku zupa garšīga, bet, manuprāt, 11€ ir mazliet par dārgu priekš šīs zupas un tās daudzuma.\n",
            "Correct answer: [('baraviku zupa', 'positive'), ('baraviku zupa', 'negative')]\n",
            "LLM answer: [('', 'zupa:positive'), ('11€', 'negative'), ('daudzuma', 'negative')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIENLAICĪGA ASPEKTU IZGŪŠANA UN TO NOSKAŅOJUMU NOTEIKŠANA AR PIEMĒRU"
      ],
      "metadata": {
        "id": "c_KP_rJITX1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "def parse_xml_full_absa_with_examples(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        if opinions is not None:\n",
        "          for opinion in opinions.findall('Opinion'):\n",
        "            target = opinion.get('target')\n",
        "            if target:\n",
        "              aspects.append(target)\n",
        "        if aspects and all(aspect.lower() != \"null\" for aspect in aspects):\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "test_data = parse_xml_full_absa_with_examples('new1.xml')\n",
        "print(test_data)\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects_predict_sentiment(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given a sentence, extract all explicit aspect terms mentioned in the sentence and predict the sentiments towards the aspects (positive, negative, neutral).\\n\"\n",
        "        \"Example:\\n\"\n",
        "        \"Sentence: Vīnu saraksts ir interesants, un tajā ir daudz labu piedāvājumu.\\n\"\n",
        "        \"Vīnu saraksts:positive, Vīnu saraksts:positive\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect1:polarity1, aspect2:polarity2\\n\"\n",
        "        \"Example: apkalpošana:positive, ēdienu:negative\\n\"\n",
        "        \"Do not provide any additional text or explanation and do not guess implicit aspects.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"google/gemma-3-27b-it:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    prediction = completion.choices[0].message.content.strip().lower()\n",
        "    return prediction\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "output_file = 'results_full_with_examples.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in test_data.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        prediction = extract_aspects_predict_sentiment(sentence_text)\n",
        "        if prediction:\n",
        "            f.write(prediction + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOqVGOsiTZsp",
        "outputId": "95c1c587-a4e2-41ab-e607-ce9be781fc17"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "5  lv_OPaps_000000002:2  Latvijas alus ir labā cenā, bet izlejamais imp...\n",
            "6  lv_OPaps_000000002:3  Cepelīni garšīgi, teikšu, ka pagaidām labākie,...\n",
            "7   lv_OPaps_00000002:4  Baraviku zupa garšīga, bet, manuprāt, 11€ ir m...\n",
            "8  lv_OPaps_000000002:5         Ķiploku grauzdiņi ir ļoti gardi un viegli.\n",
            "\n",
            " Results have been saved to results_full_with_examples.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target and target.lower() != \"null\":\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "test_data = parse_xml('new1.xml')\n",
        "print(test_data.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, prediction_list):\n",
        "    correct_results = []\n",
        "    predictions = []\n",
        "    mismatching_answers = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        predicted_aspects = prediction_list[i]['aspects']\n",
        "        predicted_sentiments = prediction_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == predicted_aspects and true_sentiments == predicted_sentiments:\n",
        "            correct_results.append(1)\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            correct_results.append(1)\n",
        "            predictions.append(0)\n",
        "            mismatching_answers.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'predicted_aspects': predicted_aspects,\n",
        "                'predicted_sentiments': predicted_sentiments\n",
        "            })\n",
        "    print(f\"\\nAccuracy: {accuracy_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nPrecision: {precision_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nRecall: {recall_score(correct_results, predictions)}\")\n",
        "    print(f\"\\nF1 score: {f1_score(correct_results, predictions)}\")\n",
        "    if mismatching_answers:\n",
        "        for mismatch in mismatching_answers:\n",
        "            print(f\"\\nSentence: {mismatch['text']}\")\n",
        "            print(f\"Correct answer: {list(zip(mismatch['true_aspects'], mismatch['true_sentiments']))}\")\n",
        "            print(f\"LLM answer: {list(zip(mismatch['predicted_aspects'], mismatch['predicted_sentiments']))}\")\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_full_with_examples.txt'\n",
        "test_data = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(test_data) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(test_data, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-ro3sQETxP1",
        "outputId": "0fc0948f-8550-4769-c337-fc58bdad880c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "\n",
            "Accuracy: 0.3333333333333333\n",
            "\n",
            "Precision: 1.0\n",
            "\n",
            "Recall: 0.3333333333333333\n",
            "\n",
            "F1 score: 0.5\n",
            "\n",
            "Sentence: Ļoti draudzīgas cenas ēdieniem un laba vietējā alus izlase.\n",
            "Correct answer: [('ēdieniem', 'positive'), ('alus izlase', 'positive')]\n",
            "LLM answer: [('cenas', 'positive'), ('alus izlase', 'positive')]\n",
            "\n",
            "Sentence: Ēdieniem īpaši garda un augstvērtīga lielopa gaļa.\n",
            "Correct answer: [('lielopa gaļa', 'positive')]\n",
            "LLM answer: [('lielopa gaļa', 'positive'), ('ēdieniem', 'positive')]\n",
            "\n",
            "Sentence: Perfekta apkalpošana, prot ieteikt lieliskus ēdienus.\n",
            "Correct answer: [('apkalpošana', 'positive')]\n",
            "LLM answer: [('', 'apkalpošana:positive'), ('ēdienus', 'positive')]\n",
            "\n",
            "Sentence: Latvijas alus ir labā cenā, bet izlejamais importa alus jau maksā ap 7€ par puslitru.\n",
            "Correct answer: [('latvijas alus', 'positive'), ('izlejamais importa alus', 'neutral')]\n",
            "LLM answer: [('latvijas alus', 'positive'), ('importa alus', 'negative')]\n",
            "\n",
            "Sentence: Baraviku zupa garšīga, bet, manuprāt, 11€ ir mazliet par dārgu priekš šīs zupas un tās daudzuma.\n",
            "Correct answer: [('baraviku zupa', 'positive'), ('baraviku zupa', 'negative')]\n",
            "LLM answer: [('baraviku zupa', 'positive'), ('zupa', 'negative'), ('daudzums', 'negative'), ('cena', 'negative')]\n",
            "\n",
            "Sentence: Ķiploku grauzdiņi ir ļoti gardi un viegli.\n",
            "Correct answer: [('ķiploku grauzdiņi', 'positive')]\n",
            "LLM answer: [('ķiploku grauzdiņi', 'positive'), ('ķiploku grauzdiņi', 'positive')]\n"
          ]
        }
      ]
    }
  ]
}
