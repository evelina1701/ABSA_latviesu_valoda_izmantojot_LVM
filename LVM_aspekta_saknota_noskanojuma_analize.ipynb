{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ASPEKTU NOSKAŅOJUMA NOTEIKŠANA"
      ],
      "metadata": {
        "id": "U-eP5McbUYoA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ParuhCC0UToz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebc3231-324a-4da6-b213-0d60522da6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "5  lv_OPaps_000000002:1  Vienīgi cenas pēdējā laikā diezgan palielināju...   \n",
            "6  lv_OPaps_000000002:2  Latvijas alus ir labā cenā, bet izlejamais imp...   \n",
            "7  lv_OPaps_000000002:3  Cepelīni garšīgi, teikšu, ka pagaidām labākie,...   \n",
            "8   lv_OPaps_00000002:4  Baraviku zupa garšīga, bet, manuprāt, 11€ ir m...   \n",
            "9  lv_OPaps_000000002:5         Ķiploku grauzdiņi ir ļoti gardi un viegli.   \n",
            "\n",
            "                                    aspects  \n",
            "0                                   [vieta]  \n",
            "1                   [ēdieniem, alus izlase]  \n",
            "2                            [lielopa gaļa]  \n",
            "3                             [apkalpošana]  \n",
            "4                        [ēdieni, dzērieni]  \n",
            "5                                    [NULL]  \n",
            "6  [Latvijas alus, izlejamais importa alus]  \n",
            "7                                [Cepelīni]  \n",
            "8            [Baraviku zupa, Baraviku zupa]  \n",
            "9                       [Ķiploku grauzdiņi]  \n",
            "vieta:positive\n",
            "ēdieniem:positive\n",
            "alus izlase:positive\n",
            "lielopa gaļa:positive\n",
            "apkalpošana:positive\n",
            "ēdieni:positive\n",
            "dzērieni:positive\n",
            "latvijas alus:positive\n",
            "izlejamais importa alus:negative\n",
            "cepelīni:positive\n",
            "baraviku zupa:positive\n",
            "baraviku zupa:positive\n",
            "ķiploku grauzdiņi:positive\n",
            "\n",
            " Results have been saved to results_sentiments.txt\n"
          ]
        }
      ],
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "def parse_xml_sentiment_pred(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                aspects.append(target)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml_sentiment_pred('new1.xml')\n",
        "print(df_test)\n",
        "\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def predict_sentiment(aspect, sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given an aspect term and a sentence, predict the sentiment towards the given aspect (positive, negative, neutral).\\n\\n\"\n",
        "        f\"Aspect term: '{aspect}'\\nSentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect:polarity\\n\"\n",
        "        \"Example: apkalpošana:positive\\n\"\n",
        "        \"Do not provide any additional text or explanation.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    pred = completion.choices[0].message.content.strip().lower()\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "    if ':' in pred:\n",
        "        return pred\n",
        "    else:\n",
        "        return f\"{aspect}:{pred}\"\n",
        "\n",
        "output_file = 'results_sentiments.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "  for idx, row in df_test.iterrows():\n",
        "    sentence_text = row['text']\n",
        "    aspect_preds = []\n",
        "    if len(row['aspects']) == 0:\n",
        "      continue\n",
        "    for aspect in row['aspects']:\n",
        "      if aspect.lower() == \"null\":\n",
        "        continue\n",
        "      pred = predict_sentiment(aspect, sentence_text)\n",
        "      print(pred)\n",
        "      aspect_preds.append(pred.strip())\n",
        "    if aspect_preds:\n",
        "      f.write(\", \".join(aspect_preds) + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target and target.lower() != \"null\":\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, pred_list):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    mismatches = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        pred_aspects = pred_list[i]['aspects']\n",
        "        pred_sentiments = pred_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == pred_aspects and true_sentiments == pred_sentiments:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(0)\n",
        "            mismatches.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'pred_aspects': pred_aspects,\n",
        "                'pred_sentiments': pred_sentiments\n",
        "            })\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nPrecision: {precision_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nRecall: {recall_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nF1 score: {f1_score(y_true, y_pred)}\")\n",
        "    if mismatches:\n",
        "        for m in mismatches:\n",
        "            print(f\"\\nTeikums: {m['text']}\")\n",
        "            print(f\"PAREIZS: {list(zip(m['true_aspects'], m['true_sentiments']))}\")\n",
        "            print(f\"MODEĻA: {list(zip(m['pred_aspects'], m['pred_sentiments']))}\")\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_sentiments.txt'\n",
        "df_test = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(df_test) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(df_test, predictions)"
      ],
      "metadata": {
        "id": "931l-hb8U71w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110d0804-9f1e-43e8-b985-993cfd63a0a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "\n",
            "Accuracy: 0.7777777777777778\n",
            "\n",
            "Precision: 1.0\n",
            "\n",
            "Recall: 0.7777777777777778\n",
            "\n",
            "F1 score: 0.875\n",
            "\n",
            "Teikums: Latvijas alus ir labā cenā, bet izlejamais importa alus jau maksā ap 7€ par puslitru.\n",
            "PAREIZS: [('latvijas alus', 'positive'), ('izlejamais importa alus', 'neutral')]\n",
            "MODEĻA: [('latvijas alus', 'positive'), ('izlejamais importa alus', 'negative')]\n",
            "\n",
            "Teikums: Baraviku zupa garšīga, bet, manuprāt, 11€ ir mazliet par dārgu priekš šīs zupas un tās daudzuma.\n",
            "PAREIZS: [('baraviku zupa', 'positive'), ('baraviku zupa', 'negative')]\n",
            "MODEĻA: [('baraviku zupa', 'positive'), ('baraviku zupa', 'positive')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ASPEKTU IZGŪŠANA"
      ],
      "metadata": {
        "id": "y8H4gW34_zE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "def parse_xml_aspect_extraction(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        data.append({\n",
        "            'id': sentence.get('id'),\n",
        "            'text': text\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml_aspect_extraction('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect term extraction.\\n\"\n",
        "        \"Given a sentence, extract all explicit aspect terms mentioned in the sentence.\\n\"\n",
        "        \"If there is no explicit aspect in a whole sentence or in an exact part of a sentence, give answer 'null'.\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY with aspect terms, comma-separated.\\n\"\n",
        "        \"Example: apkalpošana, ēdienu, null\\n\"\n",
        "        \"Do not provide any additional text or explanation and do not guess implicit aspects.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    pred = completion.choices[0].message.content.strip().lower()\n",
        "    return pred\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: kā uzlabot šo koda daļu, lai tas būtu piemērots izgūtu aspektu saglabāšanai? https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "output_file = 'results_aspects.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in df_test.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        pred_aspects = extract_aspects(sentence_text)\n",
        "        if pred_aspects:\n",
        "            f.write(pred_aspects + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3liWvuE8_1Pm",
        "outputId": "201b9b19-d5bf-44ed-a308-d1c00d55ba5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "\n",
            " Results have been saved to results_aspects.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                if target:\n",
        "                  aspects.append(target.lower())\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect, aspect formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_list = [aspect.strip().lower() for aspect in line.split(',') if aspect.strip()]\n",
        "            predictions.append({\n",
        "                'aspects': aspect_list\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, pred_list):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    mismatches = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        pred_aspects = pred_list[i]['aspects']\n",
        "        if true_aspects == pred_aspects:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(0)\n",
        "            mismatches.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'pred_aspects': pred_aspects\n",
        "            })\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nPrecision: {precision_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nRecall: {recall_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nF1 score: {f1_score(y_true, y_pred)}\")\n",
        "    if mismatches:\n",
        "        for m in mismatches:\n",
        "            print(f\"\\nTeikums: {m['text']}\")\n",
        "            print(f\"PAREIZS: {list(zip(m['true_aspects']))}\")\n",
        "            print(f\"MODEĻA: {list(zip(m['pred_aspects']))}\")\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_aspects.txt'\n",
        "df_test = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(df_test) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(df_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaIBwcwKBQbu",
        "outputId": "62685f60-e4e8-4c64-f7aa-1f6a6b780768"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects  \n",
            "0                  [vieta]  \n",
            "1  [ēdieniem, alus izlase]  \n",
            "2           [lielopa gaļa]  \n",
            "3            [apkalpošana]  \n",
            "4       [ēdieni, dzērieni]  \n",
            "\n",
            "Accuracy: 0.1\n",
            "\n",
            "Precision: 1.0\n",
            "\n",
            "Recall: 0.1\n",
            "\n",
            "F1 score: 0.18181818181818182\n",
            "\n",
            "Teikums: Lieliska vieta vakariņām.\n",
            "PAREIZS: [('vieta',)]\n",
            "MODEĻA: [('vaketa',), ('vakariņām',)]\n",
            "\n",
            "Teikums: Ļoti draudzīgas cenas ēdieniem un laba vietējā alus izlase.\n",
            "PAREIZS: [('ēdieniem',), ('alus izlase',)]\n",
            "MODEĻA: [('draudzīgas cenas ēdieniem',), ('laba vietējā alus izlase',)]\n",
            "\n",
            "Teikums: Ēdieniem īpaši garda un augstvērtīga lielopa gaļa.\n",
            "PAREIZS: [('lielopa gaļa',)]\n",
            "MODEĻA: [('garda',), ('augstvērtīga',), ('lielopa',)]\n",
            "\n",
            "Teikums: Perfekta apkalpošana, prot ieteikt lieliskus ēdienus.\n",
            "PAREIZS: [('apkalpošana',)]\n",
            "MODEĻA: [('apkalpošana',), ('ēdienus',)]\n",
            "\n",
            "Teikums: Ļoti garšīgi ēdieni un dzērieni.\n",
            "PAREIZS: [('ēdieni',), ('dzērieni',)]\n",
            "MODEĻA: [('null',)]\n",
            "\n",
            "Teikums: Vienīgi cenas pēdējā laikā diezgan palielinājušās.\n",
            "PAREIZS: [('null',)]\n",
            "MODEĻA: [('cenas',)]\n",
            "\n",
            "Teikums: Latvijas alus ir labā cenā, bet izlejamais importa alus jau maksā ap 7€ par puslitru.\n",
            "PAREIZS: [('latvijas alus',), ('izlejamais importa alus',)]\n",
            "MODEĻA: [('cenā',), ('importa alus',), ('maksā',)]\n",
            "\n",
            "Teikums: Baraviku zupa garšīga, bet, manuprāt, 11€ ir mazliet par dārgu priekš šīs zupas un tās daudzuma.\n",
            "PAREIZS: [('baraviku zupa',), ('baraviku zupa',)]\n",
            "MODEĻA: [('garšīga',), ('dārgu',)]\n",
            "\n",
            "Teikums: Ķiploku grauzdiņi ir ļoti gardi un viegli.\n",
            "PAREIZS: [('ķiploku grauzdiņi',)]\n",
            "MODEĻA: [('null',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIENLAICĪGA ASPEKTU IZGŪŠANA UN TO NOSKAŅOJUMU NOTEIKŠANA"
      ],
      "metadata": {
        "id": "4zMLdV98Mtw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "def parse_xml_full_absa(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        data.append({\n",
        "            'id': sentence.get('id'),\n",
        "            'text': text\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml_full_absa('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects_predict_sentiment(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given a sentence, extract all explicit aspect terms mentioned in the sentence and predict the sentiments towards the extracted aspects (positive, negative, neutral).\\n\\n\"\n",
        "        \"If there is no explicit aspect in a whole sentence or in an exact part of a sentence, give answer 'null'.\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect1:polarity1, aspect2:polarity2\\n\"\n",
        "        \"Example: apkalpošana:positive, null:negative\\n\"\n",
        "        \"Do not provide any additional text or explanation and do not guess implicit aspects.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"google/gemma-3-27b-it:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    pred = completion.choices[0].message.content.strip().lower()\n",
        "\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "    if ':' in pred:\n",
        "        return pred\n",
        "    else:\n",
        "        return f\"{aspect}:{pred}\"\n",
        "\n",
        "output_file = 'results_full.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in df_test.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        pred = extract_aspects_predict_sentiment(sentence_text)\n",
        "        if pred:\n",
        "            f.write(pred + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vt4_9KQMvYw",
        "outputId": "5e747ba3-46d1-41dd-e495-20c4d4a6ab66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "\n",
            " Results have been saved to results_full.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target:\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, pred_list):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    mismatches = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        pred_aspects = pred_list[i]['aspects']\n",
        "        pred_sentiments = pred_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == pred_aspects and true_sentiments == pred_sentiments:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(0)\n",
        "            mismatches.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'pred_aspects': pred_aspects,\n",
        "                'pred_sentiments': pred_sentiments\n",
        "            })\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nPrecision: {precision_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nRecall: {recall_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nF1 score: {f1_score(y_true, y_pred)}\")\n",
        "    if mismatches:\n",
        "        for m in mismatches:\n",
        "            print(f\"\\nTeikums: {m['text']}\")\n",
        "            print(f\"PAREIZS: {list(zip(m['true_aspects'], m['true_sentiments']))}\")\n",
        "            print(f\"MODEĻA: {list(zip(m['pred_aspects'], m['pred_sentiments']))}\")\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_full.txt'\n",
        "df_test = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(df_test) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(df_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vJrczm6OMlD",
        "outputId": "da9e26d7-77b9-4cf6-887a-e2d70fb245d9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "\n",
            "Accuracy: 0.3\n",
            "\n",
            "Precision: 1.0\n",
            "\n",
            "Recall: 0.3\n",
            "\n",
            "F1 score: 0.46153846153846156\n",
            "\n",
            "Teikums: Ļoti draudzīgas cenas ēdieniem un laba vietējā alus izlase.\n",
            "PAREIZS: [('ēdieniem', 'positive'), ('alus izlase', 'positive')]\n",
            "MODEĻA: [('cenas', 'positive'), ('alus izlase', 'positive')]\n",
            "\n",
            "Teikums: Perfekta apkalpošana, prot ieteikt lieliskus ēdienus.\n",
            "PAREIZS: [('apkalpošana', 'positive')]\n",
            "MODEĻA: [('apkalpošana', 'positive'), ('ēdienus', 'positive')]\n",
            "\n",
            "Teikums: Ļoti garšīgi ēdieni un dzērieni.\n",
            "PAREIZS: [('ēdieni', 'positive'), ('dzērieni', 'positive')]\n",
            "MODEĻA: [('', 'ēdieni:positive'), ('dzērieni', 'positive')]\n",
            "\n",
            "Teikums: Vienīgi cenas pēdējā laikā diezgan palielinājušās.\n",
            "PAREIZS: [('null', 'negative')]\n",
            "MODEĻA: [('cenas', 'negative')]\n",
            "\n",
            "Teikums: Latvijas alus ir labā cenā, bet izlejamais importa alus jau maksā ap 7€ par puslitru.\n",
            "PAREIZS: [('latvijas alus', 'positive'), ('izlejamais importa alus', 'neutral')]\n",
            "MODEĻA: [('alus', 'positive'), ('alus', 'negative')]\n",
            "\n",
            "Teikums: Baraviku zupa garšīga, bet, manuprāt, 11€ ir mazliet par dārgu priekš šīs zupas un tās daudzuma.\n",
            "PAREIZS: [('baraviku zupa', 'positive'), ('baraviku zupa', 'negative')]\n",
            "MODEĻA: [('zupa', 'positive'), ('11€', 'negative')]\n",
            "\n",
            "Teikums: Ķiploku grauzdiņi ir ļoti gardi un viegli.\n",
            "PAREIZS: [('ķiploku grauzdiņi', 'positive')]\n",
            "MODEĻA: [('ķiploku grauzdiņi', 'positive'), ('null', 'positive')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIENLAICĪGA ASPEKTU IZGŪŠANA UN TO NOSKAŅOJUMU NOTEIKŠANA AR PIEMĒRU"
      ],
      "metadata": {
        "id": "c_KP_rJITX1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenRouter. Sample code and API for DeepSeek V3 0324 (free). Tiešsaiste. OpenRouter. Pieejams: https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free/api. [skatīts 2025-03-29].\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "def parse_xml_full_absa_with_examples(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        data.append({\n",
        "            'id': sentence.get('id'),\n",
        "            'text': text\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml_full_absa_with_examples('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: kā man uzlabot šo kodu, lai tas izmantotu no XML izgūtos teikumus, aspektus un noskaņojumus noskaņojuma noteikšanai aspektiem un vēl novērtētu modeļa veiktspēju? https://chatgpt.com/ [izmantots 2025-03-29]\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\" # for API key\n",
        ")\n",
        "def extract_aspects_predict_sentiment(sentence):\n",
        "    prompt = (\n",
        "        \"Your task is to do aspect-based sentiment analysis.\\n\"\n",
        "        \"Given a sentence, extract all explicit aspect terms mentioned in the sentence and predict the sentiments towards the aspects (positive, negative, neutral).\\n\"\n",
        "        \"If there is no explicit aspect in a whole sentence or in an exact part of a sentence, give answer 'null'.\\n\\n\"\n",
        "        \"Example:\\n\"\n",
        "        \"Sentence: Vīnu saraksts ir interesants, un tajā ir daudz labu piedāvājumu.\\n\"\n",
        "        \"Vīnu saraksts:positive, Vīnu saraksts:positive\\n\\n\"\n",
        "        f\"Sentence: \\\"{sentence}\\\"\\n\\n\"\n",
        "        \"Respond ONLY in this exact format: aspect1:polarity1, aspect2:polarity2\\n\"\n",
        "        \"Example: apkalpošana:positive, null:negative\\n\"\n",
        "        \"Do not provide any additional text or explanation and do not guess implicit aspects.\\n\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_body={},\n",
        "        model=\"google/gemma-3-27b-it:free\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    pred = completion.choices[0].message.content.strip().lower()\n",
        "\n",
        "# OpenAI. ChatGPT o3-mini-high. Uzvedne: uzlabo manu kodu tā, lai nevis tiktu aprēķinātas precision, recall un f1 vērtības, bet iegūtie rezultāti tiktu ierakstīti failā, kurš pēc tam tiks konstanti papildināts ar citiem rezultātiem un iepriekš ierakstītie rezultāti netiks dzēsti ārā. iegūtajiem rezultātiem ir jābūt ierakstītiem tā, ka, ja teikumā ir viens aspekts, tad vienā rindiņā ir tikai aspect:polarity, bet ja ir 2 un vairāk aspektu, tad vienā rindiņā jābūt aspect1:polarity1, aspect2:polarity2. tiem ir jābūt tādā secībā, kādā ir teikumi un kādā esot aspekti pašā teikumā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "    if ':' in pred:\n",
        "        return pred\n",
        "    else:\n",
        "        return f\"{aspect}:{pred}\"\n",
        "\n",
        "output_file = 'results_full_with_examples.txt'\n",
        "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in df_test.iterrows():\n",
        "        sentence_text = row['text']\n",
        "        pred = extract_aspects_predict_sentiment(sentence_text)\n",
        "        if pred:\n",
        "            f.write(pred + \"\\n\")\n",
        "print(f\"\\n Results have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOqVGOsiTZsp",
        "outputId": "24105659-9033-480b-cc38-37f272bfc693"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.\n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...\n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...\n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...\n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.\n",
            "\n",
            " Results have been saved to results_full_with_examples.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for sentence in root.iter('sentence'):\n",
        "        text = sentence.find('text').text.strip()\n",
        "        opinions = sentence.find('Opinions')\n",
        "        aspects = []\n",
        "        sentiments = []\n",
        "        if opinions is not None:\n",
        "            for opinion in opinions.findall('Opinion'):\n",
        "                target = opinion.get('target')\n",
        "                polarity = opinion.get('polarity')\n",
        "                if target:\n",
        "                  aspects.append(target.lower())\n",
        "                  sentiments.append(polarity)\n",
        "        if aspects:\n",
        "          data.append({\n",
        "              'id': sentence.get('id'),\n",
        "              'text': text,\n",
        "              'aspects': aspects,\n",
        "              'sentiments': sentiments\n",
        "          })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_test = parse_xml('new1.xml')\n",
        "print(df_test.head())\n",
        "\n",
        "# OpenAI. GPT-4o. Uzvedne: nepieciešams pārveidot šo kodu tā, lai tiktu vēlreiz izgūti dati no XML faila, lai varētu salīdzināt pareizos rezultātus ar lielā valodas modeļa atrastajiem rezultātiem, kuri ir saglabāti atsevišķā .txt failā aspect:polarity formā, un lai tad varētu aprēķināt metriku rezultātus. Rezultāti skaitās pareizi tikai tad, ja iegūtie rezultāti pilnībā sakrīt ar īstajiem rezultātiem gan kvalitatīvā ziņā, gan kvantitatīvā ziņā https://chatgpt.com/ [izmantots 2025-04-02]\n",
        "def load_predictions(file_path):\n",
        "    predictions = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            aspect_polarity_pairs = line.split(',')\n",
        "            aspects = []\n",
        "            sentiments = []\n",
        "            for pair in aspect_polarity_pairs:\n",
        "                if ':' in pair:\n",
        "                    parts = pair.split(':', maxsplit = 1)\n",
        "                    if len(parts) != 2:\n",
        "                      continue\n",
        "                    aspect,polarity = parts\n",
        "                    aspects.append(aspect.strip())\n",
        "                    sentiments.append(polarity.strip())\n",
        "            predictions.append({\n",
        "                'aspects': aspects,\n",
        "                'sentiments': sentiments\n",
        "            })\n",
        "    return predictions\n",
        "\n",
        "def evaluate(true_df, pred_list):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    mismatches = []\n",
        "\n",
        "    for i, row in true_df.iterrows():\n",
        "        true_aspects = row['aspects']\n",
        "        true_sentiments = row['sentiments']\n",
        "\n",
        "        pred_aspects = pred_list[i]['aspects']\n",
        "        pred_sentiments = pred_list[i]['sentiments']\n",
        "\n",
        "        if true_aspects == pred_aspects and true_sentiments == pred_sentiments:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "            y_pred.append(0)\n",
        "            mismatches.append({\n",
        "                'text': row['text'],\n",
        "                'true_aspects': true_aspects,\n",
        "                'true_sentiments': true_sentiments,\n",
        "                'pred_aspects': pred_aspects,\n",
        "                'pred_sentiments': pred_sentiments\n",
        "            })\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nPrecision: {precision_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nRecall: {recall_score(y_true, y_pred)}\")\n",
        "    print(f\"\\nF1 score: {f1_score(y_true, y_pred)}\")\n",
        "    if mismatches:\n",
        "        for m in mismatches:\n",
        "            print(f\"\\nTeikums: {m['text']}\")\n",
        "            print(f\"PAREIZS: {list(zip(m['true_aspects'], m['true_sentiments']))}\")\n",
        "            print(f\"MODEĻA: {list(zip(m['pred_aspects'], m['pred_sentiments']))}\")\n",
        "\n",
        "xml_path = 'new1.xml'\n",
        "predictions_path = 'results_full_with_examples.txt'\n",
        "df_test = parse_xml(xml_path)\n",
        "predictions = load_predictions(predictions_path)\n",
        "assert len(df_test) == len(predictions), \"Teikumu skaits nesakrīt ar modeļa rezultātu skaitu!\"\n",
        "evaluate(df_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-ro3sQETxP1",
        "outputId": "3d5b5cd4-a404-4f21-a4d0-8de3e54e678d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id                                               text  \\\n",
            "0  lv_OPaps_000000001:0                          Lieliska vieta vakariņām.   \n",
            "1  lv_OPaps_000000001:1  Ļoti draudzīgas cenas ēdieniem un laba vietējā...   \n",
            "2  lv_OPaps_000000001:2  Ēdieniem īpaši garda un augstvērtīga lielopa g...   \n",
            "3  lv_OPaps_000000001:3  Perfekta apkalpošana, prot ieteikt lieliskus ē...   \n",
            "4  lv_OPaps_000000002:0                   Ļoti garšīgi ēdieni un dzērieni.   \n",
            "\n",
            "                   aspects            sentiments  \n",
            "0                  [vieta]            [positive]  \n",
            "1  [ēdieniem, alus izlase]  [positive, positive]  \n",
            "2           [lielopa gaļa]            [positive]  \n",
            "3            [apkalpošana]            [positive]  \n",
            "4       [ēdieni, dzērieni]  [positive, positive]  \n",
            "\n",
            "Accuracy: 0.4\n",
            "\n",
            "Precision: 1.0\n",
            "\n",
            "Recall: 0.4\n",
            "\n",
            "F1 score: 0.5714285714285714\n",
            "\n",
            "Teikums: Lieliska vieta vakariņām.\n",
            "PAREIZS: [('vieta', 'positive')]\n",
            "MODEĻA: [('lieliska vieta', 'positive')]\n",
            "\n",
            "Teikums: Perfekta apkalpošana, prot ieteikt lieliskus ēdienus.\n",
            "PAREIZS: [('apkalpošana', 'positive')]\n",
            "MODEĻA: [('apkalpošana', 'positive'), ('ēdienus', 'positive')]\n",
            "\n",
            "Teikums: Latvijas alus ir labā cenā, bet izlejamais importa alus jau maksā ap 7€ par puslitru.\n",
            "PAREIZS: [('latvijas alus', 'positive'), ('izlejamais importa alus', 'neutral')]\n",
            "MODEĻA: [('latvijas alus', 'positive'), ('importa alus', 'negative')]\n",
            "\n",
            "Teikums: Cepelīni garšīgi, teikšu, ka pagaidām labākie, kurus Latvijā esmu ēdis.\n",
            "PAREIZS: [('cepelīni', 'positive')]\n",
            "MODEĻA: [('cepelīni', 'positive'), ('cepelīni', 'positive')]\n",
            "\n",
            "Teikums: Baraviku zupa garšīga, bet, manuprāt, 11€ ir mazliet par dārgu priekš šīs zupas un tās daudzuma.\n",
            "PAREIZS: [('baraviku zupa', 'positive'), ('baraviku zupa', 'negative')]\n",
            "MODEĻA: [('baraviku zupa', 'positive'), ('zupas cena', 'negative'), ('zupas daudzums', 'negative')]\n",
            "\n",
            "Teikums: Ķiploku grauzdiņi ir ļoti gardi un viegli.\n",
            "PAREIZS: [('ķiploku grauzdiņi', 'positive')]\n",
            "MODEĻA: [('ķiploku grauzdiņi', 'positive'), ('ķiploku grauzdiņi', 'positive')]\n"
          ]
        }
      ]
    }
  ]
}